{"cells":[{"cell_type":"markdown","metadata":{"id":"W-_Kl0B6GIPo"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vb_bOjPrEReu","executionInfo":{"status":"ok","timestamp":1670635456226,"user_tz":300,"elapsed":781,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"}}},"outputs":[],"source":["from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":637},"executionInfo":{"elapsed":6137,"status":"ok","timestamp":1670635462357,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"Ivs09reFVd7v","outputId":"839201a4-2163-4904-ab5a-48612548e8df"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fastNLP in /usr/local/lib/python3.8/dist-packages (1.0.1)\n","Requirement already satisfied: prettytable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from fastNLP) (3.5.0)\n","Requirement already satisfied: rich==11.2.0 in /usr/local/lib/python3.8/dist-packages (from fastNLP) (11.2.0)\n","Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.8/dist-packages (from fastNLP) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastNLP) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fastNLP) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from fastNLP) (2022.6.2)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from rich==11.2.0->fastNLP) (0.4.6)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich==11.2.0->fastNLP) (2.6.1)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from rich==11.2.0->fastNLP) (0.9.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prettytable>=0.7.2->fastNLP) (0.2.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fastNLP) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fastNLP) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fastNLP) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fastNLP) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fastNLP) (2022.9.24)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n"]}],"source":["! pip install fastNLP\n","! pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":2246,"status":"ok","timestamp":1670635464573,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"wK4_P0Kg_BqK","outputId":"1283969c-66c8-482e-f8f8-06299696e8d4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":4098,"status":"ok","timestamp":1670635468661,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"nmZYIytJX4JU","outputId":"5dfb1eef-dbed-45fe-e587-96bb02435774"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"]},"metadata":{}}],"source":["from torch.utils.data import Dataset, DataLoader\n","import json\n","import torch\n","from fastNLP import Vocabulary\n","from transformers import BertTokenizer, AdamW\n","from collections import defaultdict\n","from random import choice\n","from transformers import AutoTokenizer, AutoModelForMaskedLM"]},{"cell_type":"code","source":["'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Zrle20VrbZOh","executionInfo":{"status":"ok","timestamp":1670635469117,"user_tz":300,"elapsed":464,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"}},"outputId":"1de71662-b29f-4a63-936c-b84ea8b4690a"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1670635469119,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"ysAWK6shGCiI","outputId":"83d1686b-3763-42ab-dce0-7e3f65ef0781"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["class Config:\n","    \"\"\"\n","    句子最长长度是294 这里就不设参数限制长度了,每个batch 自适应长度\n","    \"\"\"\n","\n","    def __init__(self, model_name, epochs):\n","        self.model_name = model_name\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        # self.bert_path = '../input/huggingface-bert/bert-base-chinese'\n","\n","        self.train_file = '/content/drive/MyDrive/Final Project/Datafile/train.json'\n","        self.test_file = '/content/drive/MyDrive/Final Project/Datafile/test.json'\n","        self.dev_file = '/content/drive/MyDrive/Final Project/Datafile/dev.json'\n","\n","        self.batch_size = 16\n","\n","        self.rel_dict_path = '/content/drive/MyDrive/Final Project/Datafile/rel.json'\n","        id2rel = json.load(open(self.rel_dict_path, encoding='utf8'))\n","        self.rel_vocab = Vocabulary(unknown=None, padding=None)\n","        self.rel_vocab.add_word_lst(list(id2rel.values()))  # relation to index\n","        self.num_rel = 18 \n","\n","        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n","        #self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n","        #self.tokenizer_wwn = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\n","\n","        \n","        self.learning_rate = 1e-5\n","        self.bert_dim = 768\n","        self.epochs = epochs\n","config = Config(\"hfl/chinese-bert-wwm\",5)"]},{"cell_type":"markdown","metadata":{"id":"Xicuk34D9XTa"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1670635469120,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"wcKLj6RXA_HQ","outputId":"9f7d0124-3656-46d2-a36a-499f8950b663"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["def collate_fn(batch):\n","    batch = list(zip(*batch))\n","    text = batch[0]\n","    triple = batch[1]\n","    del batch\n","    return text, triple\n","\n","class MyDataset(Dataset):\n","    def __init__(self, path):\n","        super().__init__()\n","        self.dataset = []\n","        with open(path, encoding='utf8') as F:\n","            for line in F:\n","                line = json.loads(line)\n","                self.dataset.append(line)\n","\n","    def __getitem__(self, item):\n","        content = self.dataset[item]\n","        text = content['text']\n","        spo_list = content['spo_list']\n","        return text, spo_list\n","\n","    def __len__(self):\n","        return len(self.dataset)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1252,"status":"ok","timestamp":1670635470349,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"iCN4V_CnFYKn","outputId":"0b90beb7-d9b2-408c-f78e-1aa455a63477"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["train_data = MyDataset(config.train_file)\n","test_data = MyDataset(config.test_file)\n","dev_data = MyDataset(config.dev_file)"]},{"cell_type":"code","source":["dev_data.__len__()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"UdMGJYv_1iaN","executionInfo":{"status":"ok","timestamp":1670638877839,"user_tz":300,"elapsed":259,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"}},"outputId":"e8405250-d5f5-4bcc-b5e6-2cb0e1cff223"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["11191"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1670635470361,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"EWxwE3r0PCkG","outputId":"63f65213-b5eb-48b5-9270-ab72520564ca"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["55959"]},"metadata":{},"execution_count":9}],"source":["train_data.__len__()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1670635470362,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"rFIB9PnlCpqn","outputId":"302654b2-acdd-4744-ac31-e4cc788751ef"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["13417"]},"metadata":{},"execution_count":10}],"source":["test_data.__len__()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1670635470363,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"CL5XdN0aCTyh","outputId":"66a0a853-31e2-4ae1-b68d-47d8ddd3c35a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["('笔       名：木斧原       名：杨莆曾  用  名：穆新文、牧羊、寒白、洋漾出生日期：1931—职       业：作家、诗人性    别： 男民    族： 回族政治面貌：中共党员 祖       籍：固原县出  生  地：成都', [{'predicate': '民族', 'object_type': '文本', 'subject_type': '人物', 'object': '回族', 'subject': '木斧'}, {'predicate': '出生日期', 'object_type': '日期', 'subject_type': '人物', 'object': '1931', 'subject': '木斧'}, {'predicate': '出生地', 'object_type': '地点', 'subject_type': '人物', 'object': '成都', 'subject': '木斧'}])\n"]}],"source":["for i in train_data:\n","  print(i)\n","  break;"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1670635470364,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"JIMOtsDDDVWc","outputId":"04369927-4c87-4996-d254-36cab654233f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["def create_data_iter(config):\n","    train_data = MyDataset(config.train_file)\n","    dev_data = MyDataset(config.dev_file)\n","    test_data = MyDataset(config.test_file)\n","    \n","\n","    train_iter = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n","    dev_iter = DataLoader(dev_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n","    test_iter = DataLoader(test_data, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    return train_iter, dev_iter, test_iter"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1670635470364,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"P7ef8rADcuBC","outputId":"bbc4dd3c-142d-495c-e71d-5b7a2891c245"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["train_iter = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n","for i in train_iter:\n","    text_raw, triple = i\n","    break"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1670635470365,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"76s7S-AxFtok","outputId":"2a88f879-a7ce-433c-c44a-e1304de0a0f9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('师坦，男，1966年3月出生，汉族，河北怀来人，中共党员，研究生学历，工程师、注册规划师',\n"," '《汗血宝马》是由吴子牛执导的作品，聂远参加演出',\n"," '之前第一部吴若希的《越难越爱》也不错，每次到有情感线的地方就放这首，泪流满面',\n"," '苏杰，国家二级指挥，1978年毕业于北京市艺术学校、曾进修于中央音乐学院指挥系受教于黄飞立、郑晓英、秋里、李德伦',\n"," '杨力华，男，1962年出生，中山大学数学与计算科学学院教授、博士生导师，副院长',\n"," '4月，孔维领衔主演的武侠话剧《新龙门客栈》在大连文化中心开演12',\n"," '《婚礼策划人》是2002年播出的电视剧，由武内英树，羽住英一郎导演',\n"," '乔恩·海德，男，1977年在美国中西部科罗拉多州北部的柯林斯堡出生，是临床医生詹姆斯·海德六个孩子中的老四',\n"," '山东浩信集团有限公司于2007年09月10日在昌邑市市场监督管理局登记成立',\n"," '祁永膺生于1853，去世于1905，字伯福，别字荫杰，号子服',\n"," '范业展，男，1964年出生，毕业于北京林业大学，学士学位，高级工程师',\n"," '《花落随》是李维演唱的歌曲，收录在专辑《烟花问》',\n"," '徐贇：我毕业华东交通大学艺术学院之后一直从事店面设计、商业空间设计和品牌终端形象设计',\n"," '《物联网应用启示录》是2011年机械工业出版社出版的图书，作者是陈海滢',\n"," '《电信行业节能减排技术、方法与案例》是2010年1月人民邮电出版社出版的图书，作者是秦廷奎',\n"," '亚美尼亚革命联盟1890年成立于俄罗斯帝国梯弗里斯（今[格鲁吉亚]首都第比利斯）')"]},"metadata":{},"execution_count":14}],"source":["text_raw"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1670635481218,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"wDYfOCkTHQgt","outputId":"6f46d241-9236-4521-d4d5-e1babef0e6d5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["([{'predicate': '出生地', 'object_type': '地点', 'subject_type': '人物', 'object': '河北怀来', 'subject': '师坦'}, {'predicate': '民族', 'object_type': '文本', 'subject_type': '人物', 'object': '汉族', 'subject': '师坦'}, {'predicate': '出生日期', 'object_type': '日期', 'subject_type': '人物', 'object': '1966年3月', 'subject': '师坦'}], [{'predicate': '导演', 'object_type': '人物', 'subject_type': '影视作品', 'object': '吴子牛', 'subject': '汗血宝马'}], [{'predicate': '歌手', 'object_type': '人物', 'subject_type': '歌曲', 'object': '吴若希', 'subject': '越难越爱'}], [{'predicate': '毕业院校', 'object_type': '学校', 'subject_type': '人物', 'object': '北京市艺术学校', 'subject': '苏杰'}], [{'predicate': '出生日期', 'object_type': '日期', 'subject_type': '人物', 'object': '1962年', 'subject': '杨力华'}], [{'predicate': '主演', 'object_type': '人物', 'subject_type': '影视作品', 'object': '孔维', 'subject': '新龙门客栈'}], [{'predicate': '导演', 'object_type': '人物', 'subject_type': '影视作品', 'object': '羽住英一郎', 'subject': '婚礼策划人'}, {'predicate': '导演', 'object_type': '人物', 'subject_type': '影视作品', 'object': '武内英树', 'subject': '婚礼策划人'}], [{'predicate': '国籍', 'object_type': '国家', 'subject_type': '人物', 'object': '美国', 'subject': '乔恩·海德'}], [{'predicate': '成立日期', 'object_type': '日期', 'subject_type': '企业', 'object': '2007年09月10日', 'subject': '山东浩信集团有限公司'}], [{'predicate': '出生日期', 'object_type': '日期', 'subject_type': '人物', 'object': '1853', 'subject': '祁永膺'}], [{'predicate': '毕业院校', 'object_type': '学校', 'subject_type': '人物', 'object': '北京林业大学', 'subject': '范业展'}], [{'predicate': '所属专辑', 'object_type': '音乐专辑', 'subject_type': '歌曲', 'object': '烟花问', 'subject': '花落随'}, {'predicate': '歌手', 'object_type': '人物', 'subject_type': '歌曲', 'object': '李维', 'subject': '花落随'}], [{'predicate': '毕业院校', 'object_type': '学校', 'subject_type': '人物', 'object': '华东交通大学', 'subject': '徐贇'}], [{'predicate': '出版社', 'object_type': '出版社', 'subject_type': '图书作品', 'object': '机械工业出版社', 'subject': '物联网应用启示录'}], [{'predicate': '出版社', 'object_type': '出版社', 'subject_type': '图书作品', 'object': '人民邮电出版社', 'subject': '电信行业节能减排技术、方法与案例'}], [{'predicate': '成立日期', 'object_type': '日期', 'subject_type': '机构', 'object': '1890年', 'subject': '亚美尼亚革命联盟'}])\n"]}],"source":["print(triple)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":841,"status":"ok","timestamp":1670635483349,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"u0nB_flYCX7s","outputId":"095fda5c-f18a-41e2-dc10-f57228cfadc0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["class Batch:\n","    def __init__(self, config):\n","        self.tokenizer = config.tokenizer\n","        self.num_relations = config.num_rel\n","        self.rel_vocab = config.rel_vocab\n","        self.device = config.device\n","\n","    def __call__(self, text, triple):\n","        ''' Generate inputs and labels for model training\n","        Parameters: \n","          text: raw text sentences with given batch size generated by dataloader\n","          triple: triple for sentences with given batch size generated by dataloader\n","        return:\n","          inputs -> tensor \n","          labels -> tensor\n","        '''\n","        text = self.tokenizer(text, padding=True).data\n","        batch_size = len(text['input_ids'])\n","        seq_len = len(text['input_ids'][0])\n","        sub_head = []\n","        sub_tail = []\n","        sub_heads = []\n","        sub_tails = []\n","        obj_heads = []\n","        obj_tails = []\n","        sub_len = []\n","        sub_head2tail = []\n","\n","        for batch_index in range(batch_size):\n","            inner_input_ids = text['input_ids'][batch_index]  # for each sentence index in batch \n","            inner_triples = triple[batch_index] \n","            inner_sub_heads, inner_sub_tails, inner_sub_head, inner_sub_tail, inner_sub_head2tail, inner_sub_len, inner_obj_heads, inner_obj_tails = \\\n","                self.create_label(inner_triples, inner_input_ids, seq_len)\n","            sub_head.append(inner_sub_head)\n","            sub_tail.append(inner_sub_tail)\n","            sub_len.append(inner_sub_len)\n","            sub_head2tail.append(inner_sub_head2tail)\n","            sub_heads.append(inner_sub_heads)\n","            sub_tails.append(inner_sub_tails)\n","            obj_heads.append(inner_obj_heads)\n","            obj_tails.append(inner_obj_tails)\n","\n","        input_ids = torch.tensor(text['input_ids']).to(self.device)\n","        mask = torch.tensor(text['attention_mask']).to(self.device)\n","        sub_head = torch.stack(sub_head).to(self.device)\n","        sub_tail = torch.stack(sub_tail).to(self.device)\n","        sub_heads = torch.stack(sub_heads).to(self.device)\n","        sub_tails = torch.stack(sub_tails).to(self.device)\n","        sub_len = torch.stack(sub_len).to(self.device)\n","        sub_head2tail = torch.stack(sub_head2tail).to(self.device)\n","        obj_heads = torch.stack(obj_heads).to(self.device)\n","        obj_tails = torch.stack(obj_tails).to(self.device)\n","\n","        return {\n","                   'input_ids': input_ids,\n","                   'mask': mask,\n","                   'sub_head2tail': sub_head2tail,\n","                   'sub_len': sub_len\n","               }, {\n","                   'sub_heads': sub_heads,\n","                   'sub_tails': sub_tails,\n","                   'obj_heads': obj_heads,\n","                   'obj_tails': obj_tails\n","               }\n","\n","    def create_label(self, inner_triples, inner_input_ids, seq_len):\n","        '''generate labels for given text sentence\n","        Parameters:\n","          inner_triples: triple for each sentence within the batch\n","          inner_input_ids: word index for each sentence within the batch\n","          seq_len: padding size within the batch\n","        Return:\n","          inner_sub_heads, inner_sub_tails, inner_sub_head, inner_sub_tail, inner_sub_head2tail -> tensor(seq_len)\n","          inner_obj_heads, inner_obj_tails -> tensor(seq_len, num_relations)\n","        '''\n","        inner_sub_heads, inner_sub_tails = torch.zeros(seq_len), torch.zeros(seq_len)\n","        inner_sub_head, inner_sub_tail = torch.zeros(seq_len), torch.zeros(seq_len)\n","        inner_obj_heads = torch.zeros((seq_len, self.num_relations))\n","        inner_obj_tails = torch.zeros((seq_len, self.num_relations))\n","        inner_sub_head2tail = torch.zeros(seq_len)  # 随机抽取一个实体，从开头一个词到末尾词的索引\n","\n","        # 因为数据预处理代码还待优化,会有不存在关系三元组的情况，\n","        # 初始化一个主词的长度为1，即没有主词默认主词长度为1，\n","        # 防止零除报错,初始化任何非零数字都可以，没有主词分子是全零矩阵\n","        inner_sub_len = torch.tensor([1], dtype=torch.float)\n","        # 主词到谓词的映射\n","        s2ro_map = defaultdict(list)\n","        for inner_triple in inner_triples:\n","\n","            inner_triple = (\n","                self.tokenizer(inner_triple['subject'], add_special_tokens=False)['input_ids'],\n","                self.rel_vocab.to_index(inner_triple['predicate']),\n","                self.tokenizer(inner_triple['object'], add_special_tokens=False)['input_ids']\n","            )\n","\n","            sub_head_idx = self.find_head_idx(inner_input_ids, inner_triple[0])\n","            obj_head_idx = self.find_head_idx(inner_input_ids, inner_triple[2])\n","\n","            if sub_head_idx != -1 and obj_head_idx != -1:\n","                sub = (sub_head_idx, sub_head_idx + len(inner_triple[0]) - 1)\n","                # s2ro_map保存主语到谓语的映射\n","                s2ro_map[sub].append(\n","                    (obj_head_idx, obj_head_idx + len(inner_triple[2]) - 1, inner_triple[1]))  # {(3,5):[(7,8,0)]} 0 is relation\n","\n","        if s2ro_map:\n","            for s in s2ro_map:\n","                inner_sub_heads[s[0]] = 1\n","                inner_sub_tails[s[1]] = 1\n","\n","            sub_head_idx, sub_tail_idx = choice(list(s2ro_map.keys()))\n","            inner_sub_head[sub_head_idx] = 1\n","            inner_sub_tail[sub_tail_idx] = 1\n","            inner_sub_head2tail[sub_head_idx:sub_tail_idx + 1] = 1\n","            inner_sub_len = torch.tensor([sub_tail_idx + 1 - sub_head_idx], dtype=torch.float)\n","            for ro in s2ro_map.get((sub_head_idx, sub_tail_idx), []):\n","                inner_obj_heads[ro[0]][ro[2]] = 1\n","                inner_obj_tails[ro[1]][ro[2]] = 1\n","\n","        return inner_sub_heads, inner_sub_tails, inner_sub_head, inner_sub_tail, inner_sub_head2tail, inner_sub_len, inner_obj_heads, inner_obj_tails\n","\n","    @staticmethod\n","    def find_head_idx(source, target):\n","        target_len = len(target)\n","        for i in range(len(source)):\n","            if source[i: i + target_len] == target:\n","                return i\n","        return -1"]},{"cell_type":"markdown","metadata":{"id":"jVwQjgWSzkBB"},"source":["# Modeling - CasRel\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1670635486706,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"mA8sm9CPz3H4","outputId":"5a89bc3c-99e4-47db-ef18-5fb0084d8036"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["import torch.nn as nn\n","import torch\n","from transformers import BertModel"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1670635488067,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"7x85DVp-zobs","outputId":"2d1d7f06-60eb-4515-d6d9-ba4645198adc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["class CasRel(nn.Module):\n","    def __init__(self, config):\n","        super(CasRel, self).__init__()\n","        self.config = config\n","        self.model_name = self.config.model_name\n","        #self.bert = BertModel.from_pretrained(\"bert-base-chinese\")\n","        self.bert = BertModel.from_pretrained(self.model_name)\n","        self.sub_heads_linear = nn.Linear(self.config.bert_dim, 1)\n","        self.sub_tails_linear = nn.Linear(self.config.bert_dim, 1)\n","        self.obj_heads_linear = nn.Linear(self.config.bert_dim, self.config.num_rel)\n","        self.obj_tails_linear = nn.Linear(self.config.bert_dim, self.config.num_rel)\n","        self.alpha = 0.25\n","        self.gamma = 2\n","\n","    def get_encoded_text(self, token_ids, mask):        \n","        encoded_text = self.bert(token_ids, attention_mask=mask)[0]\n","        return encoded_text\n","\n","    def get_subs(self, encoded_text):\n","        pred_sub_heads = torch.sigmoid(self.sub_heads_linear(encoded_text))\n","        pred_sub_tails = torch.sigmoid(self.sub_tails_linear(encoded_text))\n","        return pred_sub_heads, pred_sub_tails\n","\n","    def get_objs_for_specific_sub(self, sub_head2tail, sub_len, encoded_text):\n","        # sub_head_mapping [batch, 1, seq] * encoded_text [batch, seq, dim]\n","        sub = torch.matmul(sub_head2tail, encoded_text)  # batch size,1,dim\n","        sub_len = sub_len.unsqueeze(1)\n","        sub = sub / sub_len  # batch size, 1,dim\n","        encoded_text = encoded_text + sub\n","        #  [batch size, seq len,bert_dim] -->[batch size, seq len,relathion counts]\n","        pred_obj_heads = torch.sigmoid(self.obj_heads_linear(encoded_text))\n","        pred_obj_tails = torch.sigmoid(self.obj_tails_linear(encoded_text))\n","        return pred_obj_heads, pred_obj_tails\n","\n","    def forward(self, input_ids, mask, sub_head2tail, sub_len):\n","        \"\"\"\n","\n","        :param token_ids:[batch size, seq len]\n","        :param mask:[batch size, seq len]\n","        :param sub_head:[batch size, seq len]\n","        :param sub_tail:[batch size, seq len]\n","        :return:\n","        \"\"\"\n","         #mat1 and mat2 shapes cannot be multiplied (324x21128 and 768x1)\n","        encoded_text = self.get_encoded_text(input_ids, mask)\n","        pred_sub_heads, pred_sub_tails = self.get_subs(encoded_text)\n","        sub_head2tail = sub_head2tail.unsqueeze(1)  # [[batch size,1, seq len]]\n","        pred_obj_heads, pre_obj_tails = self.get_objs_for_specific_sub(sub_head2tail, sub_len, encoded_text)\n","\n","        return {\n","            \"pred_sub_heads\": pred_sub_heads,\n","            \"pred_sub_tails\": pred_sub_tails,\n","            \"pred_obj_heads\": pred_obj_heads,\n","            \"pred_obj_tails\": pre_obj_tails,\n","            'mask': mask\n","        }\n","\n","    def compute_loss(self, pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails, mask, sub_heads,\n","                     sub_tails, obj_heads, obj_tails):\n","        rel_count = obj_heads.shape[-1]\n","        rel_mask = mask.unsqueeze(-1).repeat(1, 1, rel_count)\n","        loss_1 = self.loss_fun(pred_sub_heads, sub_heads, mask)\n","        loss_2 = self.loss_fun(pred_sub_tails, sub_tails, mask)\n","        loss_3 = self.loss_fun(pred_obj_heads, obj_heads, rel_mask)\n","        loss_4 = self.loss_fun(pred_obj_tails, obj_tails, rel_mask)\n","        return loss_1 + loss_2 + loss_3 + loss_4\n","\n","    def loss_fun(self, logist, label, mask):\n","        count = torch.sum(mask)\n","        logist = logist.view(-1)\n","        label = label.view(-1)\n","        mask = mask.view(-1)\n","        \n","        alpha_factor = torch.where(torch.eq(label,1), 1- self.alpha,self.alpha)\n","        focal_weight = torch.where(torch.eq(label,1),1-logist,logist)\n","        \n","        loss = -(torch.log(logist) * label + torch.log(1 - logist) * (1 - label)) * mask\n","        return torch.sum(focal_weight * loss) / count"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1670635489903,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"sEgpvhxN0f8_","outputId":"7126fb61-fe4e-4a9c-8f43-caab71a03a3e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["\n","def load_model(config):\n","    device = config.device\n","    model = CasRel(config)\n","    model.to(device)\n","\n","    # prepare optimzier\n","    param_optimizer = list(model.named_parameters())\n","\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n","        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}]\n","\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, eps=10e-8)\n","    sheduler = None\n","\n","    return model, optimizer, sheduler, device"]},{"cell_type":"markdown","metadata":{"id":"DUx4sgtG1lBP"},"source":["# Model Training"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1670635493569,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"cFc8cnoX1uBC","outputId":"cc8ef8f1-161e-4610-c21b-ece8d7319222"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":341,"status":"ok","timestamp":1670635689179,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"uk72A6Ap1m1K","outputId":"9f182650-46a1-40b8-e7e8-0eb01f196449"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["def train_epoch(model, train_iter, dev_iter, optimizer, batch, best_triple_f1, epoch, save_path):\n","    for step, (text, triple) in enumerate(train_iter):\n","        model.train()\n","        inputs, labels = batch(text, triple)\n","        logist = model(**inputs)\n","        loss = model.compute_loss(**logist, **labels)\n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if step % 500 == 1:\n","            sub_precision, sub_recall, sub_f1, triple_precision, triple_recall, triple_f1, df = test(model, dev_iter,\n","                                                                                                     batch)\n","            if triple_f1 > best_triple_f1:\n","                best_triple_f1 = triple_f1\n","                torch.save(model.state_dict(), save_path)\n","                print(\n","                    'epoch:{},step:{},sub_precision:{:.4f}, sub_recall:{:.4f}, sub_f1:{:.4f}, triple_precision:{:.4f}, triple_recall:{:.4f}, triple_f1:{:.4f},train loss:{:.4f}'.format(\n","                        epoch, step, sub_precision, sub_recall, sub_f1, triple_precision, triple_recall, triple_f1,\n","                        loss.item()))\n","                print(df)\n","\n","    return best_triple_f1\n","\n","\n","def train(model, train_iter, dev_iter, optimizer, batch, config, save_path):\n","    epochs = config.epochs\n","    best_triple_f1 = 0\n","    for epoch in range(epochs):\n","        best_triple_f1 = train_epoch(model, train_iter, dev_iter, optimizer, batch, best_triple_f1, epoch, save_path)\n","\n","\n","def test(model, dev_iter, batch):\n","    model.eval()\n","    df = pd.DataFrame(columns=['TP', 'PRED', \"REAL\", 'p', 'r', 'f1'], index=['sub', 'triple'])\n","    df.fillna(0, inplace=True)\n","\n","    for text, triple in tqdm(dev_iter):\n","        inputs, labels = batch(text, triple)\n","        # print(\"text: \", text)\n","        # print(\"triple: \", triple)\n","        # print(\"labels: \", labels)\n","        logist = model(**inputs)\n","        \n","        pred_sub_heads = convert_score_to_zero_one(logist['pred_sub_heads'])\n","        pred_sub_tails = convert_score_to_zero_one(logist['pred_sub_tails'])\n","\n","        sub_heads = convert_score_to_zero_one(labels['sub_heads'])\n","        #print(\"labels['sub_heads']: \", labels['sub_heads'])\n","        sub_tails = convert_score_to_zero_one(labels['sub_tails'])\n","        batch_size = inputs['input_ids'].shape[0]\n","\n","        obj_heads = convert_score_to_zero_one(labels['obj_heads'])\n","        obj_tails = convert_score_to_zero_one(labels['obj_tails'])\n","        pred_obj_heads = convert_score_to_zero_one(logist['pred_obj_heads'])\n","        pred_obj_tails = convert_score_to_zero_one(logist['pred_obj_tails'])\n","\n","        for batch_index in range(batch_size):\n","            pred_subs = extract_sub(pred_sub_heads[batch_index].squeeze(), pred_sub_tails[batch_index].squeeze())\n","            #print(\"pred_subs: \", pred_subs)\n","            true_subs = extract_sub(sub_heads[batch_index].squeeze(), sub_tails[batch_index].squeeze())\n","            #print(\"true_subs: \", true_subs)\n","            pred_ojbs = extract_obj_and_rel(pred_obj_heads[batch_index], pred_obj_tails[batch_index])\n","            #print(\"pred_ojbs: \", pred_ojbs)\n","            true_objs = extract_obj_and_rel(obj_heads[batch_index], obj_tails[batch_index])\n","            #print(\"true_objs: \", true_objs)\n","\n","            df['PRED']['sub'] += len(pred_subs)\n","            df['REAL']['sub'] += len(true_subs)\n","            for true_sub in true_subs:\n","                if true_sub in pred_subs:\n","                    df['TP']['sub'] += 1\n","\n","            df['PRED']['triple'] += len(pred_ojbs)\n","            df['REAL']['triple'] += len(true_objs)\n","            for true_obj in true_objs:\n","                if true_obj in pred_ojbs:\n","                    df['TP']['triple'] += 1\n","\n","    df.loc['sub','p'] = df['TP']['sub'] / (df['PRED']['sub'] + 1e-9)\n","    df.loc['sub','r'] = df['TP']['sub'] / (df['REAL']['sub'] + 1e-9)\n","    df.loc['sub','f1'] = 2 * df['p']['sub'] * df['r']['sub'] / (df['p']['sub'] + df['r']['sub'] + 1e-9)\n","    \n","    sub_precision = df['TP']['sub'] / (df['PRED']['sub'] + 1e-9)\n","    sub_recall = df['TP']['sub'] / (df['REAL']['sub'] + 1e-9)\n","    sub_f1 = 2 * sub_precision * sub_recall  / (sub_precision + sub_recall  + 1e-9)\n","\n","    df.loc['triple','p'] = df['TP']['triple'] / (df['PRED']['triple'] + 1e-9)\n","    df.loc['triple','r'] = df['TP']['triple'] / (df['REAL']['triple'] + 1e-9)\n","    df.loc['triple','f1'] = 2 * df['p']['triple'] * df['r']['triple'] / (\n","            df['p']['triple'] + df['r']['triple'] + 1e-9)\n","    \n","    \n","    triple_precision = df['TP']['triple'] / (df['PRED']['triple'] + 1e-9)\n","    triple_recall = df['TP']['triple'] / (df['REAL']['triple'] + 1e-9)\n","    triple_f1 = 2 * triple_precision * triple_recall / (\n","            triple_precision + triple_recall + 1e-9)\n","\n","    return sub_precision, sub_recall,sub_f1, triple_precision, triple_recall, triple_f1, df\n","\n","\n","def extract_sub(pred_sub_heads, pred_sub_tails):\n","    subs = []\n","    heads = torch.arange(0, len(pred_sub_heads))[pred_sub_heads == 1].to(torch.device('cuda'))\n","    tails = torch.arange(0, len(pred_sub_tails))[pred_sub_tails == 1].to(torch.device('cuda'))\n","\n","    for head, tail in zip(heads, tails):\n","        if tail >= head:\n","            subs.append((head.item(), tail.item()))\n","    return subs\n","\n","\n","def extract_obj_and_rel(obj_heads, obj_tails):\n","    obj_heads = obj_heads.T\n","    obj_tails = obj_tails.T\n","    rel_count = obj_heads.shape[0]\n","    obj_and_rels = []  # [(rel_index,strart_index,end_index),(rel_index,strart_index,end_index)]\n","\n","    for rel_index in range(rel_count):\n","        obj_head = obj_heads[rel_index]\n","        obj_tail = obj_tails[rel_index]\n","\n","        objs = extract_sub(obj_head, obj_tail)\n","        if objs:\n","            for obj in objs:\n","                start_index, end_index = obj\n","                obj_and_rels.append((rel_index, start_index, end_index))\n","    return obj_and_rels\n","\n","\n","def convert_score_to_zero_one(tensor):\n","    tensor[tensor>=0.5] = 1\n","    tensor[tensor<0.5] = 0\n","    return tensor"]},{"cell_type":"markdown","metadata":{"id":"B-ZNfGKhF95K"},"source":["## Bert CasRel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327,"referenced_widgets":["df6e4ec8d8f6434b83da6fe968260196","30bba7024191493896e313a90adebf71","6812068a53f843aca8a87879eb00ffb7","0f28851757df4bf9af9ffb3949486500","c490655ad63a4aa3b1e11b51a46d95b7","645be48751e447ffaeb08181b52b4c0b","1f1d72ab337849ed83510f51fa660f1c","6b83c2d4af3c433abcdfb0d79246d58e","3b98007d622748c2ba769eb873cd852c","2394576ac76349efad183b8822b15d83","e4a60538e35049aa902106df7b3e3016","950f1c907ed74291b267bb4ab16b2081","9ccbf0d6b7e54f34a81bffc255d34c24","bfbfe098207f4163831238c7a9464fb1","ba2fd1f2f77b40c188ef199d632af439","d5fcd65c74194129a2c5abcb89424b75","abe88fd00d2748188929916490ed5efb","b2edcbaf6839488cb950ba11e65575af","b2c585130fad4780ab7b702966da5f60","e759e68d10b44024b304e9ba9ca2db03","e645c028edbe4670a482ba8d3590225e","ee6701c9d8ba4ae7bf679c1126cc1333","646df9971a384778a6b66fca5d29cdcf","3af23d22d9c0431dbff2760490917b64","d57dc451a79d4ec68eef67ced88137dc","a32d1e5222a740188e905a2bdadfb55d","bf6d8f058f814517b1c1cbfcc7c056b6","f28285a0e2674e2cb896b263b0c4b193","f1b5ea3989904cf88d367dc79929035b","f69090425cfb41108312d056bb4ddc5b","fd1ca5405d3e42e8ad0db358887d8d4e","dd66cd3b8fe2465c93ef84e24c2a648e","f02f3303476b4920a359939d33abc2ac","31e17cb8df58424fb6075ce8c54b3c52","64447d284eb74f58993643b169a02bd1","49e26c2ed9f546b4953f80816c43a702","04c0e9f5cd58458cae99d9769c2e9a7a","fdf4b85aab984929a1cdaaa2c6b2eacb","6d3f695b081242cb8075925f3fb15908","598870a7d38f4c428632e6d4dcf70728","27206ab5919842ca91d06d97fe70e7f3","72759c4bd32445a6bf516b1324486d96","0998790a91da4e29ba8b75a6c32410a8","05a80215790d41a0b059c16e35738cf8"]},"executionInfo":{"elapsed":44298,"status":"ok","timestamp":1670088690531,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"znQIHzUqddYV","outputId":"f1a55b16-9349-491a-f66a-37531ece053f"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df6e4ec8d8f6434b83da6fe968260196","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/110k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"950f1c907ed74291b267bb4ab16b2081","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"646df9971a384778a6b66fca5d29cdcf","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/624 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31e17cb8df58424fb6075ce8c54b3c52","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/412M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["config = Config(\"bert-base-chinese\",8)\n","train_data = MyDataset(config.train_file)\n","bert_base_model, optimizer, sheduler, device = load_model(config)\n","train_iter, dev_iter, test_iter = create_data_iter(config)\n","batch = Batch(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":9227354,"status":"ok","timestamp":1670046151296,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"tyfI3NLZi7fx","outputId":"59b6ad80-3b49-470c-ab0b-b66c069a4a25"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [02:28<00:00,  4.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:0,step:1,sub_precision:0.0005, sub_recall:0.0066, sub_f1:0.0010, triple_precision:0.0000, triple_recall:0.0047, triple_f1:0.0001,train loss:1.3757\n","        TP     PRED   REAL         p         r        f1\n","sub     78   142565  11759  0.000547  0.006633  0.001011\n","triple  77  1929978  16230  0.000040  0.004744  0.000079\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:52<00:00,  6.20it/s]\n","100%|██████████| 700/700 [01:53<00:00,  6.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:0,step:1001,sub_precision:0.8917, sub_recall:0.8814, sub_f1:0.8865, triple_precision:0.8314, triple_recall:0.1479, triple_f1:0.2511,train loss:0.0427\n","           TP   PRED   REAL         p         r        f1\n","sub     10364  11623  11759  0.891680  0.881367  0.886494\n","triple   2401   2888  16238  0.831371  0.147863  0.251072\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:55<00:00,  6.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:0,step:1501,sub_precision:0.8723, sub_recall:0.8911, sub_f1:0.8816, triple_precision:0.7107, triple_recall:0.4174, triple_f1:0.5259,train loss:0.0170\n","           TP   PRED   REAL         p         r        f1\n","sub     10478  12012  11759  0.872294  0.891062  0.881578\n","triple   6776   9534  16233  0.710720  0.417421  0.525944\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:56<00:00,  6.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:0,step:2001,sub_precision:0.8945, sub_recall:0.8803, sub_f1:0.8873, triple_precision:0.6799, triple_recall:0.5510, triple_f1:0.6087,train loss:0.0152\n","           TP   PRED   REAL         p         r        f1\n","sub     10351  11572  11759  0.894487  0.880262  0.887317\n","triple   8947  13159  16237  0.679915  0.551025  0.608722\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:55<00:00,  6.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:0,step:2501,sub_precision:0.9247, sub_recall:0.8787, sub_f1:0.9011, triple_precision:0.7267, triple_recall:0.5384, triple_f1:0.6185,train loss:0.0064\n","           TP   PRED   REAL         p         r        f1\n","sub     10333  11175  11759  0.924653  0.878731  0.901108\n","triple   8736  12022  16227  0.726668  0.538362  0.618500\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:56<00:00,  6.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:0,step:3001,sub_precision:0.8309, sub_recall:0.9025, sub_f1:0.8652, triple_precision:0.6608, triple_recall:0.6864, triple_f1:0.6733,train loss:0.0083\n","           TP   PRED   REAL         p         r        f1\n","sub     10612  12771  11759  0.830945  0.902458  0.865226\n","triple  11141  16860  16232  0.660795  0.686360  0.673335\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:56<00:00,  6.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:1,step:1,sub_precision:0.8966, sub_recall:0.8794, sub_f1:0.8879, triple_precision:0.7072, triple_recall:0.6445, triple_f1:0.6744,train loss:0.0115\n","           TP   PRED   REAL         p         r        f1\n","sub     10341  11534  11759  0.896567  0.879412  0.887906\n","triple  10466  14799  16240  0.707210  0.644458  0.674377\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:56<00:00,  5.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:1,step:501,sub_precision:0.9109, sub_recall:0.9020, sub_f1:0.9065, triple_precision:0.6687, triple_recall:0.7143, triple_f1:0.6907,train loss:0.0157\n","           TP   PRED   REAL         p         r        f1\n","sub     10607  11644  11759  0.910941  0.902032  0.906465\n","triple  11593  17337  16230  0.668685  0.714295  0.690738\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:1,step:1501,sub_precision:0.9126, sub_recall:0.9099, sub_f1:0.9113, triple_precision:0.6988, triple_recall:0.6935, triple_f1:0.6961,train loss:0.0083\n","           TP   PRED   REAL         p         r        f1\n","sub     10700  11725  11759  0.912580  0.909941  0.911259\n","triple  11257  16110  16231  0.698759  0.693549  0.696144\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:56<00:00,  6.00it/s]\n","100%|██████████| 700/700 [01:56<00:00,  6.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:1,step:2501,sub_precision:0.8932, sub_recall:0.9192, sub_f1:0.9060, triple_precision:0.6949, triple_recall:0.7361, triple_f1:0.7149,train loss:0.0095\n","           TP   PRED   REAL         p         r        f1\n","sub     10809  12101  11759  0.893232  0.919211  0.906035\n","triple  11946  17192  16229  0.694858  0.736090  0.714880\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:56<00:00,  5.99it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:56<00:00,  5.99it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:56<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:3,step:1001,sub_precision:0.9316, sub_recall:0.9412, sub_f1:0.9364, triple_precision:0.6459, triple_recall:0.8059, triple_f1:0.7171,train loss:0.0047\n","           TP   PRED   REAL         p         r        f1\n","sub     11068  11880  11759  0.931650  0.941236  0.936419\n","triple  13072  20237  16220  0.645946  0.805919  0.717119\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:56<00:00,  5.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:3,step:2001,sub_precision:0.8988, sub_recall:0.9445, sub_f1:0.9211, triple_precision:0.6533, triple_recall:0.8043, triple_f1:0.7210,train loss:0.0091\n","           TP   PRED   REAL         p         r        f1\n","sub     11106  12356  11759  0.898835  0.944468  0.921086\n","triple  13051  19978  16227  0.653269  0.804277  0.720950\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:56<00:00,  6.00it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:4,step:501,sub_precision:0.9287, sub_recall:0.9520, sub_f1:0.9402, triple_precision:0.6584, triple_recall:0.8011, triple_f1:0.7228,train loss:0.0087\n","           TP   PRED   REAL         p         r        f1\n","sub     11195  12054  11759  0.928737  0.952037  0.940243\n","triple  13004  19750  16232  0.658430  0.801134  0.722806\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch:4,step:1501,sub_precision:0.9054, sub_recall:0.9656, sub_f1:0.9346, triple_precision:0.6696, triple_recall:0.8101, triple_f1:0.7331,train loss:0.0033\n","           TP   PRED   REAL         p         r        f1\n","sub     11355  12541  11759  0.905430  0.965643  0.934568\n","triple  13144  19631  16226  0.669553  0.810058  0.733134\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:56<00:00,  5.99it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:58<00:00,  5.93it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.95it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.98it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.96it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.94it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.94it/s]\n","100%|██████████| 700/700 [01:57<00:00,  5.97it/s]\n"]}],"source":["train(bert_base_model, train_iter, dev_iter, optimizer, batch, config, 'base_best_f1.pth')\n","torch.save(bert_base_model, 'base_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"elapsed":10938,"status":"ok","timestamp":1670088701411,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"Ux5pYxmtc94i","outputId":"6a272173-0530-44ce-cb8c-0f169e79199e"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["bert_base_model, optimizer, sheduler, device = load_model(config)\n","bert_base_model.load_state_dict(torch.load('/content/drive/MyDrive/Final Project/base_best_f1.pth'))"]},{"cell_type":"markdown","metadata":{"id":"3zVteIwiGLpb"},"source":["### Test Result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":160370,"status":"ok","timestamp":1670088868926,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"FQo1roNOZ1Mz","outputId":"c2d2bdde-700b-469a-bf0d-39a4feee34e4"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [02:40<00:00,  4.37it/s]\n"]}],"source":["sub_precision, sub_recall,sub_f1, triple_precision, triple_recall, triple_f1, df = test(bert_base_model, dev_iter, batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1670088868930,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"L9j-IuqAeFck","outputId":"9e208908-f13a-417f-8187-f3a4f8884c6f"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-8463497f-0d64-410d-bd70-a107c2b42488\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TP</th>\n","      <th>PRED</th>\n","      <th>REAL</th>\n","      <th>p</th>\n","      <th>r</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sub</th>\n","      <td>11174</td>\n","      <td>11709</td>\n","      <td>11759</td>\n","      <td>0.954309</td>\n","      <td>0.950251</td>\n","      <td>0.952275</td>\n","    </tr>\n","    <tr>\n","      <th>triple</th>\n","      <td>13108</td>\n","      <td>19446</td>\n","      <td>16247</td>\n","      <td>0.674072</td>\n","      <td>0.806795</td>\n","      <td>0.734486</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8463497f-0d64-410d-bd70-a107c2b42488')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8463497f-0d64-410d-bd70-a107c2b42488 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8463497f-0d64-410d-bd70-a107c2b42488');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           TP   PRED   REAL         p         r        f1\n","sub     11174  11709  11759  0.954309  0.950251  0.952275\n","triple  13108  19446  16247  0.674072  0.806795  0.734486"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"9u67WAsFGOPU"},"source":["## Bert Whole Word Mask CasRel"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":199},"id":"7HnIRjzQZCdX","outputId":"4089eaa8-6f80-467d-e33a-a8d93b13d94f","executionInfo":{"status":"ok","timestamp":1670635697512,"user_tz":300,"elapsed":3718,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at hfl/chinese-bert-wwm were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["config = Config(\"hfl/chinese-bert-wwm\",8)\n","train_data = MyDataset(config.train_file)\n","bert_wwn_model, optimizer, sheduler, device = load_model(config)\n","train_iter, dev_iter, test_iter = create_data_iter(config)\n","batch = Batch(config)\n","train(bert_wwn_model, train_iter, dev_iter, optimizer, batch, config, 'wwm_best_f1.pth')\n","torch.save(bert_wwn_model, 'wwm_model')"]},{"cell_type":"markdown","metadata":{"id":"T7iQyAmCGU4C"},"source":["### Test Result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":121148,"status":"ok","timestamp":1670057032502,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"PUs_1bWsCcbk","outputId":"35d0c582-6e47-431b-a594-373193930fc4"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [02:01<00:00,  5.78it/s]\n"]}],"source":["sub_precision, sub_recall,sub_f1, triple_precision, triple_recall, triple_f1, df = test(bert_wwn_model, dev_iter, batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1670057032503,"user":{"displayName":"Lu Zhang","userId":"15604403706736941986"},"user_tz":300},"id":"Pc81JhK64xQp","outputId":"b70c360d-e655-4403-bf9d-c56ea6eb1ed4"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-1d45d719-e864-43f0-a278-9d16e48ff933\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TP</th>\n","      <th>PRED</th>\n","      <th>REAL</th>\n","      <th>p</th>\n","      <th>r</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sub</th>\n","      <td>11545</td>\n","      <td>12097</td>\n","      <td>11759</td>\n","      <td>0.954369</td>\n","      <td>0.981801</td>\n","      <td>0.967891</td>\n","    </tr>\n","    <tr>\n","      <th>triple</th>\n","      <td>12922</td>\n","      <td>18468</td>\n","      <td>16224</td>\n","      <td>0.699697</td>\n","      <td>0.796474</td>\n","      <td>0.744956</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d45d719-e864-43f0-a278-9d16e48ff933')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1d45d719-e864-43f0-a278-9d16e48ff933 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1d45d719-e864-43f0-a278-9d16e48ff933');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           TP   PRED   REAL         p         r        f1\n","sub     11545  12097  11759  0.954369  0.981801  0.967891\n","triple  12922  18468  16224  0.699697  0.796474  0.744956"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3mX49mB5bli"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyM69AOg/8vPyIWpSYKmIYHU"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"04c0e9f5cd58458cae99d9769c2e9a7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0998790a91da4e29ba8b75a6c32410a8","placeholder":"​","style":"IPY_MODEL_05a80215790d41a0b059c16e35738cf8","value":" 412M/412M [00:24&lt;00:00, 17.0MB/s]"}},"05a80215790d41a0b059c16e35738cf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0998790a91da4e29ba8b75a6c32410a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f28851757df4bf9af9ffb3949486500":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2394576ac76349efad183b8822b15d83","placeholder":"​","style":"IPY_MODEL_e4a60538e35049aa902106df7b3e3016","value":" 110k/110k [00:00&lt;00:00, 147kB/s]"}},"1f1d72ab337849ed83510f51fa660f1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2394576ac76349efad183b8822b15d83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27206ab5919842ca91d06d97fe70e7f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30bba7024191493896e313a90adebf71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_645be48751e447ffaeb08181b52b4c0b","placeholder":"​","style":"IPY_MODEL_1f1d72ab337849ed83510f51fa660f1c","value":"Downloading: 100%"}},"31e17cb8df58424fb6075ce8c54b3c52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64447d284eb74f58993643b169a02bd1","IPY_MODEL_49e26c2ed9f546b4953f80816c43a702","IPY_MODEL_04c0e9f5cd58458cae99d9769c2e9a7a"],"layout":"IPY_MODEL_fdf4b85aab984929a1cdaaa2c6b2eacb"}},"3af23d22d9c0431dbff2760490917b64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f28285a0e2674e2cb896b263b0c4b193","placeholder":"​","style":"IPY_MODEL_f1b5ea3989904cf88d367dc79929035b","value":"Downloading: 100%"}},"3b98007d622748c2ba769eb873cd852c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49e26c2ed9f546b4953f80816c43a702":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27206ab5919842ca91d06d97fe70e7f3","max":411577189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72759c4bd32445a6bf516b1324486d96","value":411577189}},"598870a7d38f4c428632e6d4dcf70728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64447d284eb74f58993643b169a02bd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d3f695b081242cb8075925f3fb15908","placeholder":"​","style":"IPY_MODEL_598870a7d38f4c428632e6d4dcf70728","value":"Downloading: 100%"}},"645be48751e447ffaeb08181b52b4c0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"646df9971a384778a6b66fca5d29cdcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3af23d22d9c0431dbff2760490917b64","IPY_MODEL_d57dc451a79d4ec68eef67ced88137dc","IPY_MODEL_a32d1e5222a740188e905a2bdadfb55d"],"layout":"IPY_MODEL_bf6d8f058f814517b1c1cbfcc7c056b6"}},"6812068a53f843aca8a87879eb00ffb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b83c2d4af3c433abcdfb0d79246d58e","max":109540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b98007d622748c2ba769eb873cd852c","value":109540}},"6b83c2d4af3c433abcdfb0d79246d58e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d3f695b081242cb8075925f3fb15908":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72759c4bd32445a6bf516b1324486d96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"950f1c907ed74291b267bb4ab16b2081":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ccbf0d6b7e54f34a81bffc255d34c24","IPY_MODEL_bfbfe098207f4163831238c7a9464fb1","IPY_MODEL_ba2fd1f2f77b40c188ef199d632af439"],"layout":"IPY_MODEL_d5fcd65c74194129a2c5abcb89424b75"}},"9ccbf0d6b7e54f34a81bffc255d34c24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abe88fd00d2748188929916490ed5efb","placeholder":"​","style":"IPY_MODEL_b2edcbaf6839488cb950ba11e65575af","value":"Downloading: 100%"}},"a32d1e5222a740188e905a2bdadfb55d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd66cd3b8fe2465c93ef84e24c2a648e","placeholder":"​","style":"IPY_MODEL_f02f3303476b4920a359939d33abc2ac","value":" 624/624 [00:00&lt;00:00, 26.5kB/s]"}},"abe88fd00d2748188929916490ed5efb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2c585130fad4780ab7b702966da5f60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2edcbaf6839488cb950ba11e65575af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba2fd1f2f77b40c188ef199d632af439":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e645c028edbe4670a482ba8d3590225e","placeholder":"​","style":"IPY_MODEL_ee6701c9d8ba4ae7bf679c1126cc1333","value":" 29.0/29.0 [00:00&lt;00:00, 1.32kB/s]"}},"bf6d8f058f814517b1c1cbfcc7c056b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfbfe098207f4163831238c7a9464fb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2c585130fad4780ab7b702966da5f60","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e759e68d10b44024b304e9ba9ca2db03","value":29}},"c490655ad63a4aa3b1e11b51a46d95b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d57dc451a79d4ec68eef67ced88137dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f69090425cfb41108312d056bb4ddc5b","max":624,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd1ca5405d3e42e8ad0db358887d8d4e","value":624}},"d5fcd65c74194129a2c5abcb89424b75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd66cd3b8fe2465c93ef84e24c2a648e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6e4ec8d8f6434b83da6fe968260196":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30bba7024191493896e313a90adebf71","IPY_MODEL_6812068a53f843aca8a87879eb00ffb7","IPY_MODEL_0f28851757df4bf9af9ffb3949486500"],"layout":"IPY_MODEL_c490655ad63a4aa3b1e11b51a46d95b7"}},"e4a60538e35049aa902106df7b3e3016":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e645c028edbe4670a482ba8d3590225e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e759e68d10b44024b304e9ba9ca2db03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee6701c9d8ba4ae7bf679c1126cc1333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f02f3303476b4920a359939d33abc2ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1b5ea3989904cf88d367dc79929035b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f28285a0e2674e2cb896b263b0c4b193":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f69090425cfb41108312d056bb4ddc5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd1ca5405d3e42e8ad0db358887d8d4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fdf4b85aab984929a1cdaaa2c6b2eacb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}